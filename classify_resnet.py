# -*- coding: utf-8 -*-
"""classify_resnet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B03hjylhqUx-uKNwA3cwRTfMpdt9nR-K
"""

import tensorflow as tf 
import numpy as np
import matplotlib.pyplot as plt 
IMG_SIZE=(224,224)
test_dir = "flower_photos_test/"
datagen_kwargs = dict(rescale=1./255, validation_split=.20)
valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)
valid_generator = valid_datagen.flow_from_directory(
    test_dir, 
    subset="validation", 
    shuffle=True,
    target_size=IMG_SIZE
)

dataset_labels = sorted(valid_generator.class_indices.items(), key=lambda pair:pair[1])
dataset_labels = np.array([key.title() for key, value in dataset_labels])
val_image_batch, val_label_batch = next(iter(valid_generator))
true_label_ids = np.argmax(val_label_batch, axis=-1)

# Load TFLite model and see some details about input/output
TFLITE_MODEL='resnet_hub_quant.tflite'
tflite_interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL)
print("Model Load Successfuly !")
input_details = tflite_interpreter.get_input_details()
output_details = tflite_interpreter.get_output_details()

print("====================== Input details ====================== ")
print("name:", input_details[0]['name'])
print("shape:", input_details[0]['shape'])
print("type:", input_details[0]['dtype'])

print("\n====================== Output details ======================")
print("name:", output_details[0]['name'])
print("shape:", output_details[0]['shape'])
print("type:", output_details[0]['dtype'])

tflite_interpreter.resize_tensor_input(input_details[0]['index'], (32, 224, 224, 3))
tflite_interpreter.resize_tensor_input(output_details[0]['index'], (32, 5))
tflite_interpreter.allocate_tensors()

input_details = tflite_interpreter.get_input_details()
output_details = tflite_interpreter.get_output_details()

print("====================== Input details ======================")
print("name:", input_details[0]['name'])
print("shape:", input_details[0]['shape'])
print("type:", input_details[0]['dtype'])

print("\n====================== Output details ======================")
print("name:", output_details[0]['name'])
print("shape:", output_details[0]['shape'])
print("type:", output_details[0]['dtype'])

tflite_interpreter.set_tensor(input_details[0]['index'], val_image_batch)

tflite_interpreter.invoke()


tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])
tflite_model_predictions=tf.nn.softmax(tflite_model_predictions)
print("Prediction results shape:", tflite_model_predictions.shape)

# Print images batch and labels predictions for TFLite Model
tflite_model_predictions=np.array(tflite_model_predictions)
tflite_predicted_ids = np.argmax(tflite_model_predictions, axis=-1)
tflite_predicted_labels = dataset_labels[tflite_predicted_ids]
tflite_label_id = np.argmax(val_label_batch, axis=-1)

plt.figure(figsize=(10,9))
plt.subplots_adjust(hspace=0.5)
for n in range(32):
  plt.subplot(8,4,n+1)
  plt.imshow(val_image_batch[n])
  color = "green" if tflite_predicted_ids[n] == true_label_ids[n] else "red"
  plt.title(tflite_predicted_labels[n].title(), color=color)
  plt.axis('off')
_ = plt.suptitle("TFLite Quantization model  predictions (green: correct, red: incorrect)")

f=0
p=0
for i in range(len(tflite_predicted_ids)):
    if tflite_predicted_ids[i] == true_label_ids[i]:
        p=p+1
    else:
        f=f+1
print ("accuracy : {:.2f} %".format((p)/(p+f)*100))